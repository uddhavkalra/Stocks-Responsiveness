{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_data = pd.read_excel(\"Data/CRSP_fund.xlsx\")\n",
    "crsp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e80a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_data2 = crsp_data[['Date','Fund Identifier','CUSIP (8-digit)','Fund Name', 'index_fund_flag']]\n",
    "crsp_cols = ['Date', 'fundid(CRSP)', 'fund_CUSIP', 'fundname(CRSP)', 'indexflag']\n",
    "crsp_data2.columns = crsp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ffc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_flag_funds = crsp_data2[crsp_data2['indexflag'].isin(['B', 'D'])]\n",
    "index_flag_funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3359d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lseg_data, lseg_meta = pyreadstat.read_dta(\"Data/LSEG_fund.dta\")\n",
    "lseg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5881fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lseg_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed38a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lseg_data2 = lseg_data[lseg_data['shrout2'].isna() == False]\n",
    "lseg_data3 = lseg_data2[['fdate','fundno', 'fundname','cusip','stkname', 'ticker','shrout2']]\n",
    "lseg_cols = ['Date', 'fundid(LSEG)', 'fundname(LSEG)', 'stock_CUSIP', 'stock_name', 'ticker', 'shares_outstanding(1000s)']\n",
    "lseg_data3.columns = lseg_cols\n",
    "lseg_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_flag_funds['Date'] = pd.to_datetime(index_flag_funds['Date'])\n",
    "lseg_data3['Date'] = pd.to_datetime(lseg_data3['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lseg_data3 = lseg_data3[lseg_data3['Date'] >= \"2022-01-01\"]\n",
    "lseg_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRSP_WFICN = pd.read_excel(\"Data/CRSP_WFICN.xlsx\")\n",
    "CRSP_WFICN2 = CRSP_WFICN[['Fund Identifier', 'Wharton Financial Instution Center Number']]\n",
    "CRSP_WFICN2.columns = ['fundid(CRSP)', 'wficn']\n",
    "CRSP_WFICN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec41da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_flag_funds2 = pd.merge(index_flag_funds, CRSP_WFICN2, how = \"inner\", on=\"fundid(CRSP)\")\n",
    "index_flag_funds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbee634",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNDNO_WFICN = pd.read_stata(\"Data/FUNDO_WFICN.dta\")\n",
    "FUNDNO_WFICN2 = FUNDNO_WFICN[['fundno', 'wficn']]\n",
    "FUNDNO_WFICN2.columns = ['fundid(LSEG)', 'wficn']\n",
    "FUNDNO_WFICN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26097136",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNDNO_WFICN3 = FUNDNO_WFICN2.drop_duplicates(subset=['wficn', 'fundid(LSEG)'], keep='first').reset_index(drop=True)\n",
    "FUNDNO_WFICN3 = FUNDNO_WFICN3.dropna()\n",
    "FUNDNO_WFICN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "lseg_data4 = pd.merge(lseg_data3, FUNDNO_WFICN3, how = \"left\", on = 'fundid(LSEG)')\n",
    "lseg_data4 = lseg_data4.dropna()\n",
    "lseg_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f036dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lseg_data4['Date'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(index_flag_funds2, lseg_data4, on=['Date', 'wficn'], how='inner')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872af890",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_data = (merged_data.groupby(['Date', 'ticker'])['shares_outstanding(1000s)'].sum().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55370383",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_data.columns = ['Date', 'ticker', 'sharesheldpassive(1000s)']\n",
    "passive_data['shares_held_passive'] = passive_data['sharesheldpassive(1000s)'] * 1000 #check\n",
    "passive_data_22 = passive_data.drop(columns=['sharesheldpassive(1000s)'])\n",
    "passive_data_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23875f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_data_22.to_csv(\"Data/passive_22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180afcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can start from here\n",
    "passive_data_22 = pd.read_csv(\"Data/passive_22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_data2 = passive_data_22.dropna()\n",
    "passive_data3 = passive_data2[['Date', 'ticker', 'shares_held_passive']]\n",
    "passive_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_dates = pd.read_excel(\"Data/LSEG_earnings.xlsx\")\n",
    "earnings_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_dates2 = earnings_dates[['oftic', 'Period End Date, SAS Format' ,'Announce Date, SAS Format', 'Announce time, SAS Format']]\n",
    "earnings_dates2.columns = ['ticker', 'quarter' ,'earnings_date', 'earnings_time']\n",
    "earnings_dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ca1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_dates2['earnings_date'] = pd.to_datetime(earnings_dates2['earnings_date'])\n",
    "earnings_dates2['earnings_time'] = pd.to_datetime(earnings_dates2['earnings_time'], format='%H:%M:%S').dt.time\n",
    "earnings_dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_dates2['nextday'] = earnings_dates2['earnings_time'] > pd.to_datetime('16:30:00', format='%H:%M:%S').time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if earnings_dates2['nextday'].any() == True:\n",
    "    earnings_dates2['earnings_date'] = earnings_dates2['earnings_date'] + pd.Timedelta(days=1)\n",
    "\n",
    "earnings_dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_dates3 = earnings_dates2.drop(columns=['earnings_time', 'nextday', 'quarter'])\n",
    "earnings_dates3['Date'] = earnings_dates3['earnings_date']\n",
    "earnings_dates3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = pd.read_stata(\"Data/daily_stock.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ff6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = stock_data[stock_data['date'] >= \"2022-01-01\"]\n",
    "stock_data['date'] = pd.to_datetime(stock_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_colnames = [\"permno\", \"Date\", \"ticker\", \"company\", \"cusip\", \"price\", \"vol\", \"return\", \"shares_outstnading(1000s)\"]\n",
    "stock_data.columns = stock_colnames\n",
    "stock_data[\"shares_outstanding\"] = stock_data[\"shares_outstnading(1000s)\"] * 1000000 #check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data2 = stock_data.drop(\"shares_outstnading(1000s)\", axis = 1)\n",
    "stock_data3 = stock_data2.dropna()\n",
    "stock_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prices = stock_data3[(stock_data3.duplicated(subset=['ticker','Date'], keep=False)) &(stock_data3['price'] < 0)]\n",
    "negative_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data3 = stock_data3[stock_data3['price'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data3 = stock_data3.sort_values(['ticker','Date','shares_outstanding'], ascending=[True, True, False])\n",
    "stock_data3 = stock_data3.drop_duplicates(subset=['ticker','Date'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_data3['ticker'] = passive_data3['ticker'].astype(str)\n",
    "passive_data3['ticker'] = passive_data3['ticker'].str.upper()\n",
    "stock_data3['ticker'] = stock_data3['ticker'].astype(str)\n",
    "stock_data3['ticker'] = stock_data3['ticker'].str.upper()\n",
    "passive_data3['Date'] = pd.to_datetime(passive_data3['Date'])\n",
    "stock_data3['Date'] = pd.to_datetime(stock_data3['Date'])\n",
    "passive_data3 = passive_data3.sort_values(['ticker', 'Date']).reset_index(drop=True)\n",
    "stock_data3 = stock_data3.sort_values(['ticker', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb304e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(stock_data3, passive_data3, on = ['ticker', 'Date'], how = 'left')\n",
    "merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151deb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge1.copy()\n",
    "merge2['QuarterEnd'] = merge2['Date'].dt.to_period('Q').dt.end_time\n",
    "merge2['shares_held_passive'] = (merge2.groupby(['ticker', 'QuarterEnd'])['shares_held_passive']\n",
    "    .transform(lambda x: x.ffill().bfill() if x.notna().any() else x))\n",
    "merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3 = merge2.dropna()\n",
    "merge3 = merge3.drop(columns=['QuarterEnd'])\n",
    "merge3['share_passive'] = merge3['shares_held_passive']/merge3['shares_outstanding']\n",
    "merge3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge4 = pd.merge(merge3, earnings_dates3, on = ['Date', 'ticker'], how = 'left')\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "greaterthan1 = merge3[merge3['share_passive'] >= 1]\n",
    "problem_tickers = greaterthan1['ticker'].unique()\n",
    "totaltickers = merge3['ticker'].unique()\n",
    "print(f\"total:{len(totaltickers)}, problems: {len(problem_tickers)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
