{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load funds index/non-index data\n",
    "crsp_data = pd.read_excel(\"Data/CRSP_fund.xlsx\")\n",
    "crsp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e80a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crsp_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset data and rename columns for ease\n",
    "crsp_data2 = crsp_data[['Date','Fund Identifier','CUSIP (8-digit)','Fund Name', 'index_fund_flag']]\n",
    "crsp_cols = ['Date', 'fundid(CRSP)', 'fund_CUSIP', 'fundname(CRSP)', 'indexflag']\n",
    "crsp_data2.columns = crsp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ffc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only select the index funds (B and D)\n",
    "index_flag_funds = crsp_data2[crsp_data2['indexflag'].isin(['D'])]\n",
    "index_flag_funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3359d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load funds holdings data\n",
    "lseg_data, lseg_meta = pyreadstat.read_dta(\"Data/LSEG_fund.dta\")\n",
    "lseg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5881fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lseg_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed38a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset data and rename columns for ease\n",
    "lseg_data2 = lseg_data[lseg_data['shrout2'].isna() == False]\n",
    "lseg_data3 = lseg_data2[['fdate','fundno', 'fundname','cusip','stkname', 'ticker','shrout2']]\n",
    "lseg_cols = ['Date', 'fundid(LSEG)', 'fundname(LSEG)', 'stock_CUSIP', 'stock_name', 'ticker', 'shares_outstanding']\n",
    "lseg_data3.columns = lseg_cols\n",
    "lseg_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date columns to datetime format\n",
    "index_flag_funds['Date'] = pd.to_datetime(index_flag_funds['Date'])\n",
    "lseg_data3['Date'] = pd.to_datetime(lseg_data3['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data from 2021 onwards\n",
    "lseg_data3 = lseg_data3[lseg_data3['Date'] >= \"2021-01-01\"]\n",
    "lseg_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load WFICN to CRSP mapping data\n",
    "CRSP_WFICN = pd.read_excel(\"Data/CRSP_WFICN.xlsx\")\n",
    "CRSP_WFICN2 = CRSP_WFICN[['Fund Identifier', 'Wharton Financial Instution Center Number']]\n",
    "CRSP_WFICN2.columns = ['fundid(CRSP)', 'wficn']\n",
    "CRSP_WFICN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec41da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with index funds data\n",
    "index_flag_funds2 = pd.merge(index_flag_funds, CRSP_WFICN2, how = \"inner\", on=\"fundid(CRSP)\")\n",
    "index_flag_funds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbee634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load WFICN to LSEG mapping data\n",
    "FUNDNO_WFICN = pd.read_stata(\"Data/FUNDO_WFICN.dta\")\n",
    "FUNDNO_WFICN2 = FUNDNO_WFICN[['fundno', 'wficn']]\n",
    "FUNDNO_WFICN2.columns = ['fundid(LSEG)', 'wficn']\n",
    "FUNDNO_WFICN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26097136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates and missing values\n",
    "FUNDNO_WFICN3 = FUNDNO_WFICN2.drop_duplicates(subset=['wficn', 'fundid(LSEG)'], keep='first').reset_index(drop=True)\n",
    "FUNDNO_WFICN3 = FUNDNO_WFICN3.dropna()\n",
    "FUNDNO_WFICN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with funds holdings data\n",
    "lseg_data4 = pd.merge(lseg_data3, FUNDNO_WFICN3, how = \"left\", on = 'fundid(LSEG)')\n",
    "lseg_data4 = lseg_data4.dropna()\n",
    "lseg_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make funds dataset\n",
    "merged_data = pd.merge(index_flag_funds2, lseg_data4, on=['Date', 'wficn'], how='inner')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872af890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum over to get each stock passively held\n",
    "passive_data = (merged_data.groupby(['Date', 'ticker'])['shares_outstanding'].sum().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55370383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset data and rename columns for ease\n",
    "passive_data.columns = ['Date', 'ticker', 'shares_held_passive']\n",
    "passive_data_21 = passive_data.copy()\n",
    "passive_data_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23875f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv so that don't need to load the big datasets again\n",
    "passive_data_21.to_csv(\"Data/passive_21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180afcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data, new starting point\n",
    "passive_data_21 = pd.read_csv(\"Data/passive_21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na\n",
    "passive_data2 = passive_data_21.dropna()\n",
    "passive_data3 = passive_data2[['Date', 'ticker', 'shares_held_passive']]\n",
    "passive_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load earnings dates data\n",
    "earnings_dates = pd.read_excel(\"Data/LSEG_earnings.xlsx\")\n",
    "earnings_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename and subset columns for ease\n",
    "earnings_dates2 = earnings_dates[['oftic', 'Period End Date, SAS Format' ,'Announce Date, SAS Format', 'Announce time, SAS Format']]\n",
    "earnings_dates2.columns = ['ticker', 'quarter' ,'earnings_date', 'earnings_time']\n",
    "earnings_dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ca1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to datetime format\n",
    "earnings_dates2['earnings_date'] = pd.to_datetime(earnings_dates2['earnings_date'])\n",
    "earnings_dates2['earnings_time'] = pd.to_datetime(earnings_dates2['earnings_time'], format='%H:%M:%S').dt.time\n",
    "earnings_dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if earnings time is after mkt close consider it next day\n",
    "earnings_dates2['nextday'] = earnings_dates2['earnings_time'] > pd.to_datetime('16:30:00', format='%H:%M:%S').time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change earnings date to next day if after mkt close\n",
    "if earnings_dates2['nextday'].any() == True:\n",
    "    earnings_dates2['earnings_date'] = earnings_dates2['earnings_date'] + pd.Timedelta(days=1)\n",
    "\n",
    "earnings_dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset and add additional Date column for merging\n",
    "earnings_dates3 = earnings_dates2.drop(columns=['earnings_time', 'nextday', 'quarter'])\n",
    "earnings_dates3['Date'] = earnings_dates3['earnings_date']\n",
    "earnings_dates3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stock data\n",
    "stock_data = pd.read_stata(\"Data/daily_stock.dta\")\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ff6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to relevant time and convert date to datetime format\n",
    "stock_data['DlyCalDt'] = pd.to_datetime(stock_data['DlyCalDt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns and create shares outstanding column\n",
    "stock_colnames = [\"permno\", \"cusip1\", \"cusip2\", \"ticker\", \"permco\", \"company\", \"Date2\", \"Date\", \"price\", \"return\", \"vol\", \"shares_outstnading(1000s)\", \"sp_ret\"]\n",
    "stock_data.columns = stock_colnames\n",
    "stock_data[\"shares_outstanding\"] = stock_data[\"shares_outstnading(1000s)\"] * 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset and drop na\n",
    "stock_data2 = stock_data.drop(\"shares_outstnading(1000s)\", axis = 1)\n",
    "stock_data3 = stock_data2.dropna()\n",
    "stock_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find negative prices\n",
    "negative_prices = stock_data3[(stock_data3.duplicated(subset=['ticker','Date'], keep=False)) &(stock_data3['price'] < 0)]\n",
    "negative_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove negative prices\n",
    "stock_data3 = stock_data3[stock_data3['price'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates keeping the one with highest shares outstanding, after check those seem more reasonable\n",
    "stock_data3 = stock_data3.sort_values(['ticker','Date','shares_outstanding'], ascending=[True, True, False])\n",
    "stock_data3 = stock_data3.drop_duplicates(subset=['ticker','Date'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data for merge\n",
    "passive_data3['ticker'] = passive_data3['ticker'].astype(str)\n",
    "passive_data3['ticker'] = passive_data3['ticker'].str.upper()\n",
    "stock_data3['ticker'] = stock_data3['ticker'].astype(str)\n",
    "stock_data3['ticker'] = stock_data3['ticker'].str.upper()\n",
    "passive_data3['Date'] = pd.to_datetime(passive_data3['Date'])\n",
    "stock_data3['Date'] = pd.to_datetime(stock_data3['Date'])\n",
    "passive_data3 = passive_data3.sort_values(['ticker', 'Date']).reset_index(drop=True)\n",
    "stock_data3 = stock_data3.sort_values(['ticker', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb304e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets\n",
    "merge1 = pd.merge(stock_data3, passive_data3, on = ['ticker', 'Date'], how = 'left')\n",
    "merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151deb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backfill passive holdings for each stock for each quarter\n",
    "merge2 = merge1.copy()\n",
    "merge2['QuarterEnd'] = merge2['Date'].dt.to_period('Q').dt.end_time\n",
    "merge2['shares_held_passive'] = (merge2.groupby(['ticker', 'QuarterEnd'])['shares_held_passive']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na and create share passive column\n",
    "merge3 = merge2.dropna()\n",
    "merge3 = merge3.drop(columns=['QuarterEnd'])\n",
    "merge3['share_passive'] = merge3['shares_held_passive']/merge3['shares_outstanding']\n",
    "merge3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b644126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep data for merge\n",
    "earnings_dates3['ticker'] = earnings_dates3['ticker'].astype(str)\n",
    "earnings_dates3['ticker'] = earnings_dates3['ticker'].str.upper()\n",
    "earnings_dates3['Date'] = pd.to_datetime(earnings_dates3['Date'])\n",
    "earnings_dates3 = earnings_dates3.sort_values(['ticker', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge\n",
    "merge4 = pd.merge(merge3, earnings_dates3, on = ['Date', 'ticker'], how = 'left')\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923da0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify stocks with no earnings dates\n",
    "no_earn_tickers = merge4.groupby('ticker')['earnings_date'].apply(lambda x: x.notna().any() == False)\n",
    "no_earn_tickers = no_earn_tickers[no_earn_tickers].index.tolist()\n",
    "len(no_earn_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stocks with no earnings dates\n",
    "merge4 = merge4[~merge4['ticker'].isin(no_earn_tickers)].copy()\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fcfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new column for next earnings date\n",
    "merge4['earnings_next'] = (merge4.groupby('ticker')['earnings_date'].transform(lambda x: x.bfill()))\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31568a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new column for previous earnings date\n",
    "merge4['earnings_prev'] = (merge4.groupby('ticker')['earnings_date'].transform(lambda x: x.ffill()))\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#days since previous and until next earnings date\n",
    "merge4['days_since_prev'] = (merge4['Date'] - merge4['earnings_prev']).dt.days\n",
    "merge4['days_until_next'] = (merge4['earnings_next'] - merge4['Date']).dt.days\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1815ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to choose nearest earnings date\n",
    "def choose_nearest(row):\n",
    "    # If both exist, pick the closer date in absolute time\n",
    "    if pd.notna(row['earnings_prev']) and pd.notna(row['earnings_next']):\n",
    "        return row['earnings_prev'] if abs(row['days_since_prev']) <= abs(row['days_until_next']) else row['earnings_next']\n",
    "    # If only one exists, use it\n",
    "    elif pd.notna(row['earnings_prev']):\n",
    "        return row['earnings_prev']\n",
    "    elif pd.notna(row['earnings_next']):\n",
    "        return row['earnings_next']\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e22eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function\n",
    "merge4['earnings_date_nearest'] = merge4.apply(choose_nearest, axis=1)\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create day to/from nearest earnings date\n",
    "merge4['days_from_earn'] = (merge4['Date'] - merge4['earnings_date_nearest']).dt.days\n",
    "merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cffa871",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset data\n",
    "merge5 = merge4[['Date', 'ticker', 'price', 'vol', 'return', 'share_passive', 'shares_outstanding', 'days_from_earn', 'sp_ret', 'earnings_date_nearest']]\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5['return_lag1'] = merge5.groupby('ticker')['return'].shift(1)\n",
    "merge5['sd_3day'] = merge5.groupby('ticker')['price'].rolling(window=3).std().reset_index(level=0, drop=True)\n",
    "merge5['3day_vol'] = merge5['sd_3day']\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74be1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5['sd_5day'] = merge5.groupby('ticker')['price'].rolling(window=5).std().reset_index(level=0, drop=True)\n",
    "merge5['5day_vol'] = merge5['sd_5day']\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1620a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5['sd_7day'] = merge5.groupby('ticker')['price'].rolling(window=7).std().reset_index(level=0, drop=True)\n",
    "merge5['7day_vol'] = merge5['sd_7day']\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5 = merge5.dropna()\n",
    "X = merge5[['return_lag1']]\n",
    "y = merge5['return']\n",
    "ar1 = LinearRegression().fit(X, y)\n",
    "exp_returns_ar1 = ar1.predict(X)\n",
    "merge5['exp_return_ar1'] = exp_returns_ar1\n",
    "merge5['abnormal_return_ar1'] = merge5['return'] - merge5['exp_return_ar1']\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5 = merge5.drop(['return_lag1', 'sd_3day', 'sd_5day', 'sd_7day', 'exp_return_ar1'], axis = 1)\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5['mkt_cap'] = merge5['price'] * merge5['shares_outstanding']\n",
    "total_mkt_cap = merge5.groupby('Date')['mkt_cap'].transform('sum')\n",
    "merge5['mkt_weight'] = np.where(total_mkt_cap > 0, merge5['mkt_cap'] / total_mkt_cap, 0)\n",
    "merge5['mkt_return'] = merge5['return'] * merge5['mkt_weight']\n",
    "merge5['mkt_return'] = merge5.groupby('Date')['mkt_return'].transform('sum')\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge5 = merge5.dropna()\n",
    "X = merge5[['mkt_return']]\n",
    "y = merge5['return']\n",
    "market_model = LinearRegression().fit(X, y)\n",
    "exp_returns_mkt = market_model.predict(X)\n",
    "merge5['exp_return_mkt'] = exp_returns_mkt\n",
    "merge5['abnormal_return_mkt'] = merge5['return'] - merge5['exp_return_mkt']\n",
    "merge5 = merge5.drop(['mkt_cap', 'mkt_weight', 'mkt_return', 'exp_return_mkt'], axis = 1)\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merge5[['sp_ret']]\n",
    "y = merge5['return']\n",
    "sp_model = LinearRegression().fit(X, y)\n",
    "exp_returns_sp = sp_model.predict(X)\n",
    "merge5['exp_return_sp'] = exp_returns_sp\n",
    "merge5['abnormal_return_sp'] = merge5['return'] - merge5['exp_return_sp']\n",
    "merge5 = merge5.drop(['exp_return_sp'], axis = 1)\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = (\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies#S&P_500_component_stocks\")\n",
    "headers = {\"User-Agent\":\"Chrome/120.0.0.0 wikidatasource/1.0 (email@email.com) for thesis\"}\n",
    "response = requests.get(link, headers=headers)\n",
    "in_sp = pd.read_html(response.text)\n",
    "sp1 = in_sp[0]\n",
    "ch_sp = in_sp[1]\n",
    "sp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2 = sp1[['Symbol']]\n",
    "sp2['Date'] = \"2025-03-31\"\n",
    "sp2.columns = ['ticker', 'Date']\n",
    "sp2['Date'] = pd.to_datetime(sp2['Date'])\n",
    "sp3 = sp2.dropna()\n",
    "sp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea6d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_adds = ch_sp.T.reset_index().iloc[0:2, 2:].T\n",
    "sp_adds.columns = ['Date', 'ticker']\n",
    "sp_adds['Date'] = pd.to_datetime(sp_adds['Date'])\n",
    "sp_adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_adds2 = sp_adds[sp_adds['Date'] >= \"2021-01-01\"]\n",
    "sp_adds3 = sp_adds2.dropna()\n",
    "sp_adds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_removed = ch_sp.T.reset_index().iloc[[0,3], 2:].T\n",
    "sp_removed.columns = ['Date', 'ticker']\n",
    "sp_removed['Date'] = pd.to_datetime(sp_removed['Date'])\n",
    "sp_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc11262",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_removed2 = sp_removed[sp_removed['Date'] >= \"2021-01-01\"]\n",
    "sp_removed3 = sp_removed2.dropna()\n",
    "sp_removed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = sp_adds3['Date'].unique()\n",
    "len(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a91736",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dates = pd.date_range(start=\"2021-01-01\", end=\"2025-03-31\", freq=\"D\")\n",
    "event_dates = sorted(unique_dates, reverse=True)\n",
    "current_members = set(sp3['ticker'])\n",
    "sp_dict = {}\n",
    "\n",
    "for d in event_dates:\n",
    "    sp_dict[d] = pd.DataFrame({'Date': d, 'ticker': list(current_members)})\n",
    "    adds = sp_adds3.loc[sp_adds3['Date'] == d, 'ticker']\n",
    "    removes = sp_removed3.loc[sp_removed3['Date'] == d, 'ticker']\n",
    "    current_members.difference_update(adds)\n",
    "    current_members.update(removes)\n",
    "\n",
    "sp_event_panel = pd.concat(sp_dict.values(), ignore_index=True)\n",
    "\n",
    "sp_event_panel['Date'] = pd.to_datetime(sp_event_panel['Date'])\n",
    "sp_event_panel = sp_event_panel.sort_values('Date')\n",
    "\n",
    "event_sorted = sorted(sp_event_panel['Date'].unique())\n",
    "\n",
    "daily_records = []\n",
    "current_set = set()\n",
    "\n",
    "for d in full_dates:\n",
    "    while event_sorted and d >= event_sorted[0]:\n",
    "        current_set = set(sp_event_panel.loc[sp_event_panel['Date'] == event_sorted[0], 'ticker'])\n",
    "        event_sorted.pop(0)\n",
    "    if current_set:\n",
    "        for t in current_set:\n",
    "            daily_records.append({'Date': d, 'ticker': t})\n",
    "\n",
    "sp_daily_panel = pd.DataFrame(daily_records)\n",
    "sp_daily_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6640c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_daily_panel['ticker_sp'] = sp_daily_panel['ticker']\n",
    "merge6 = pd.merge(merge5, sp_daily_panel, on=['Date', 'ticker'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd631f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge6['in_sp'] = 0\n",
    "for i in range(len(merge6)):\n",
    "    if merge6.iloc[i, 16] == merge6.iloc[i, 1]:\n",
    "        merge6.iloc[i, 17] = 1\n",
    "merge6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13078e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge6 = merge6.drop(['ticker_sp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any share passive greater than 100\n",
    "greaterthan1 = merge6[merge6['share_passive'] >= 100]\n",
    "problem_tickers = greaterthan1['ticker'].unique()\n",
    "totaltickers = merge6['ticker'].unique()\n",
    "print(f\"total:{len(totaltickers)}, problems: {len(problem_tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb685f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove those with share passive greater than 100\n",
    "master_data1 = merge6[merge6['share_passive'] < 0.95] #maybe 1.0 or 0.9?\n",
    "master_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create event window\n",
    "master_data2 = master_data1[(master_data1['days_from_earn'] >= -31) & (master_data1['days_from_earn'] <= 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data2 = master_data2.sort_values(['ticker', 'earnings_date_nearest', 'days_from_earn']).copy()\n",
    "master_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data3 = master_data1[(master_data1['days_from_earn'] >= -21) & (master_data1['days_from_earn'] <= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data3['total_cum_ar1'] = master_data3.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_ar1'].transform('sum')\n",
    "master_data3['total_cum_mkt'] = master_data3.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_mkt'].transform('sum')\n",
    "master_data3['total_cum_sp'] = master_data3.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_sp'].transform('sum')\n",
    "master_data3 = master_data3[(master_data3['days_from_earn'] >=-1) & (master_data3['days_from_earn'] <= 5)]\n",
    "master_data3['cum_pre_post_ar1'] = master_data3.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_ar1'].transform('sum')\n",
    "master_data3['cum_pre_post_mkt'] = master_data3.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_mkt'].transform('sum')\n",
    "master_data3['cum_pre_post_sp'] = master_data3.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_sp'].transform('sum')\n",
    "master_data3['cum_pre_post_ar1'] = abs(master_data3['cum_pre_post_ar1'])\n",
    "master_data3['total_cum_ar1'] = abs(master_data3['total_cum_ar1'])\n",
    "master_data3['cum_pre_post_mkt'] = abs(master_data3['cum_pre_post_mkt'])\n",
    "master_data3['total_cum_mkt'] = abs(master_data3['total_cum_mkt'])\n",
    "master_data3['cum_pre_post_sp'] = abs(master_data3['cum_pre_post_sp'])\n",
    "master_data3['total_cum_sp'] = abs(master_data3['total_cum_sp'])\n",
    "master_data3['PJ_ar1'] = master_data3['cum_pre_post_ar1'] / master_data3['total_cum_ar1']\n",
    "master_data3['PJ_mkt'] = master_data3['cum_pre_post_mkt'] / master_data3['total_cum_mkt']\n",
    "master_data3['PJ_sp'] = master_data3['cum_pre_post_sp'] / master_data3['total_cum_sp']\n",
    "master_data3 = master_data3.drop(['total_cum_ar1', 'cum_pre_post_ar1', 'total_cum_mkt', 'cum_pre_post_mkt', 'total_cum_sp', 'cum_pre_post_sp'], axis = 1)\n",
    "master_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data3 = master_data3[master_data3['days_from_earn'] == -1]\n",
    "master_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a08b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_data = pd.read_stata(\"Data/fundamentals.dta\")\n",
    "fundamentals_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_cols = ['costat', 'currency', 'datafmt', 'indfmt', 'consolidation', 'ticker', 'Date', 'globalid', 'name', 'cusip', 'sector', 'ca', 'ta', 'capr1q', 'capr2q', 'cash_sinvest', 'comp_inc', 'long_debt', 'long_debt_tot', 'eps', 'long_invest', 'cl', 'tl', 'net_inc', 'rev']\n",
    "fundamentals_data.columns = fundamentals_cols\n",
    "fundamentals_data2 = fundamentals_data.copy()\n",
    "fundamentals_data2['Date'] = pd.to_datetime(fundamentals_data2['Date'])\n",
    "fundamentals_data3 = fundamentals_data2[['Date', 'ticker', 'sector', 'ca', 'ta', 'cash_sinvest', 'comp_inc', 'long_debt_tot', 'eps', 'long_invest', 'cl', 'tl', 'net_inc', 'rev']]\n",
    "fundamentals_data4 = fundamentals_data3[fundamentals_data3['Date'] <= '2025-03-31']\n",
    "fundamentals_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_data5 = fundamentals_data4[['Date', 'ticker', 'sector', 'ta', 'cash_sinvest', 'long_debt_tot', 'rev', 'net_inc', 'eps']]\n",
    "fundamentals_data5 = fundamentals_data5.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data4 = pd.merge(master_data1, fundamentals_data5, how = 'left', on = ['Date', 'ticker'])\n",
    "master_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dada53",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data4['QuarterEnd'] = master_data4['Date'].dt.to_period('Q').dt.end_time\n",
    "master_data4['sector'] = (master_data4.groupby(['ticker', 'QuarterEnd'])['sector']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "master_data4['ta'] = (master_data4.groupby(['ticker', 'QuarterEnd'])['ta']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "master_data4['cash_sinvest'] = (master_data4.groupby(['ticker', 'QuarterEnd'])['cash_sinvest']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "master_data4['long_debt_tot'] = (master_data4.groupby(['ticker', 'QuarterEnd'])['long_debt_tot']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "master_data4['rev'] = (master_data4.groupby(['ticker', 'QuarterEnd'])['rev']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "master_data4['net_inc'] = (master_data4.groupby(['ticker', 'QuarterEnd'])['net_inc']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "master_data4['eps'] = (master_data4.groupby(['ticker', 'QuarterEnd'])['eps']\n",
    "    .transform(lambda x: x.bfill() if x.notna().any() else x))\n",
    "master_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data5 = master_data4.drop(['QuarterEnd'], axis = 1)\n",
    "master_data5 = master_data5.dropna()\n",
    "master_data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data6 = master_data5[(master_data5['days_from_earn'] >= -31) & (master_data5['days_from_earn'] <= 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f481a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data6 = master_data6.sort_values(['ticker', 'earnings_date_nearest', 'days_from_earn']).copy()\n",
    "master_data6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf37174",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data7 = master_data5[(master_data5['days_from_earn'] >= -21) & (master_data5['days_from_earn'] <= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data7['total_cum_ar1'] = master_data7.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_ar1'].transform('sum')\n",
    "master_data7['total_cum_mkt'] = master_data7.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_mkt'].transform('sum')\n",
    "master_data7['total_cum_sp'] = master_data7.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_sp'].transform('sum')\n",
    "master_data7 = master_data7[(master_data7['days_from_earn'] >=-1) & (master_data7['days_from_earn'] <= 5)]\n",
    "master_data7['cum_pre_post_ar1'] = master_data7.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_ar1'].transform('sum')\n",
    "master_data7['cum_pre_post_mkt'] = master_data7.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_mkt'].transform('sum')\n",
    "master_data7['cum_pre_post_sp'] = master_data7.groupby(['ticker', 'earnings_date_nearest'])['abnormal_return_sp'].transform('sum')\n",
    "master_data7['cum_pre_post_ar1'] = abs(master_data7['cum_pre_post_ar1'])\n",
    "master_data7['total_cum_ar1'] = abs(master_data7['total_cum_ar1'])\n",
    "master_data7['cum_pre_post_mkt'] = abs(master_data7['cum_pre_post_mkt'])\n",
    "master_data7['total_cum_mkt'] = abs(master_data7['total_cum_mkt'])\n",
    "master_data7['cum_pre_post_sp'] = abs(master_data7['cum_pre_post_sp'])\n",
    "master_data7['total_cum_sp'] = abs(master_data7['total_cum_sp'])\n",
    "master_data7['PJ_ar1'] = master_data7['cum_pre_post_ar1'] / master_data7['total_cum_ar1']\n",
    "master_data7['PJ_mkt'] = master_data7['cum_pre_post_mkt'] / master_data7['total_cum_mkt']\n",
    "master_data7['PJ_sp'] = master_data7['cum_pre_post_sp'] / master_data7['total_cum_sp']\n",
    "master_data7 = master_data7.drop(['total_cum_ar1', 'cum_pre_post_ar1', 'total_cum_mkt', 'cum_pre_post_mkt', 'total_cum_sp', 'cum_pre_post_sp'], axis = 1)\n",
    "master_data7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data7 = master_data7[master_data7['days_from_earn'] == -1]\n",
    "master_data7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data2.to_csv(\"Data/master_data_es.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc32395",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data3.to_csv(\"Data/master_data_pj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ea1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data1.to_csv(\"Data/master_data_iv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data6.to_csv(\"Data/master_data_es_controls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ccd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data7.to_csv(\"Data/master_data_pj_controls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a160d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data5.to_csv(\"Data/master_data_iv_controls.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
